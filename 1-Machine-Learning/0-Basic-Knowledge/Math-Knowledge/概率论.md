[toc]

## 基础

概率P是对一个事件而言的，A是一个时间，P(A)就是这个事件发生的概率



$X, Y$ 是一对随机变量（Random Variable），$x, y$ 是它们分别的一个实现（Realization），他们的值可以取在 $\mathcal{X} \times \mathcal{Y}$ 空间（Space）。

第一个关键点是 分布，可以用 $P_X, P_Y$ 表示，是随机变量的分布。同时也会有联合分布 $P_{(X,Y)}$。

第二个关键点是 概率，因为分布的落脚点最终在概率（概率函数），这里离散的和连续的理解方式稍有区别。

对于离散随机变量，可以说取某一值时的概率，也就是$P(X=x)$ ，这里的概率标准应该叫做 概率质量函数，可能会见到的写法有，$p_X(x)$ 或者 $f_X(x)$。

对于连续随机变量，我们就不再谈一个点上的概率，而是一个区域，但我们可以用一个连续函数来表示，记法跟上述是一致的。



我们说这些随机变量是服从某一分布的，表示为 $P_X, P_Y$，通常我们会通过一系列的实现来估计这个分布。





$P(x;\beta)$ ：$\beta$ 是 $x$ 的参数，然后表示 $x$ 出现的概率

$P(x \mid y)$ ：条件概率

$P(x,y)$ : 联合概率

简写可以把下标去掉。



例如高斯函数，就可以用 $p(x;\mu,\sigma)$ 来表示，因为 $\mu, \sigma$ 都是参数。





## 概率函数

概率质量函数：Probability mass function (PMF)，分布律

概率密度函数：Probability density function (PDF)

累积分布函数：Cumulative distribution function (CDF)



**PMF**是针对离散随机变量而言的，是随机变量在各特定取值上的概率

> 例如抛骰子，每一面朝上的概率都是1/6，那么表示出的PMF就是：
>
> $f_{X}(x)=\left\{\begin{array}{l}{\frac{1}{6} \text { if } x \in\{1,2,3,4,5,6\}} \\ {0 \text { if } x \notin\{1,2,3,4,5,6\}}\end{array}\right.$



**PDF**是针对连续随机变量而言的，因为连续所以我们无法描述变量落在某一点上的概率，只能说落在某一区间上的概率，官方描述为：在某个确定的取值点附近的可能性的函数

我们经常看到的均匀分布，高斯分布，说的就是概率密度函数。

> 例如均匀分布，它的概率密度函数是：
>
> $f_X(x)=\left\{\begin{array}{ll}{\frac{1}{b-a}} & {\text { for } a \leq x \leq b} \\ {0} & {\text { elsewhere }}\end{array}\right.$
>
> ![1567845043390](https://img-blog.csdnimg.cn/20190920095635829.png)
>
> 如果我们说落在每一点上的概率是$\frac{1}{b-a}$，那么岂不是（b-a）个点就使得总概率为1了吗？所以并不是这样，应该是PDF函数的积分才是1，也即PDF函数图像的面积。



**CDF**是概率密度函数的积分

$F(x)=P(X<=x)$





## 期望和方差







the **expectation** of $f(x)$ , denoted by $\mathbb{E}[f]$ : the average value of some function $f(x)$ under a probability distribution $p(x)$.

for a discrete distribution
$$
\mathbb{E}[f]=\sum_{x} p(x) f(x)
$$
for a continuous distribution
$$
\mathbb{E}[f]=\int p(x) f(x) \mathrm{d} x
$$



条件概率


$$
\mathbb{E}(X|Y=y) = \sum_x x P(X=x|Y=y)
$$

$$
\begin{gather}
\mathbb{E}[S] = \sum_s s P(S=s) \\
\mathbb{E}[S|N=n] = \sum_s s P(S=s|N=n) \\
\mathbb{E}[S|N] = \sum_n n P(S|N=n) \\
\mathbb{E}[S|N] = \sum_n (S|N=n) P(N=n)
\end{gather}
$$

$$
\begin{aligned}
\mathbb{E}[\mathbb{E}[S|N]]
&= \sum_s s P\left(\sum_n n P(S=s|N=n)\right) \\
&= \sum_s s \sum_n n P(S=s|N=n)
\end{aligned}
$$


---





期望的完整形式





条件概率的期望


$$
E(Z|X) = \sum_Z p(Z|X)
$$
不是一个值，是关于X的函数。







## 定理

### 大数定律

在随机事件的大量重复出现中，往往呈现几乎必然的规律，也即在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。



### 中心极限定理

> Central limit theorem (CLT)

大量相互独立随机变量的均值经适当标准化后依分布收敛于正态分布



- 棣莫佛－拉普拉斯定理 (de Moivre - Laplace)

  参数为$n, p$的二项分布以$np$为均值、$np(1-p)$为方差的正态分布为极限

  

- 林德伯格－列维定理 (Lindeberg-Levy)

  独立同分布、且数学期望和方差有限的随机变量序列的标准化和以标准正态分布为极限

  

- 林德伯格-费勒定理

  满足一定条件时，独立，但不同分布的随机变量序列的标准化和依然以标准正态分布为极限

  

  林德伯格条件 (Lindeberg condition)：








## 全期望公式

$$
\begin{aligned}
\mathbb{E}[\mathbb{E}[X|Y]]
&= \sum_y \mathbb{E}[X|Y=y] P(Y=y)\\
&= \sum_y \sum_x x P(X=x|Y=y) P(Y=y) \\
&= \sum_x x \sum_y P(X=x|Y=y) P(Y=y) \\
&= \sum_x x P(X=x)  \\
&= \mathbb{E}[X]
\end{aligned}
$$







## 信息论

> all $\log$ is base 2



















- a set of training examples: $T = \{(\mathbf{x}^1, y^1), (\mathbf{x}^2, y^2), \dots, (\mathbf{x}^n, y^n)\}$, and $y^i \in Y$

- each of the form: $(\mathbf{x}^i, y^i) = (x^i_1, x^i_2, \dots, x^i_m, y^i)$

- where $x^i_j$ is the value of the $j^{th}$ attribute (named $a_j$) of $\mathbf{x}^i$, and $x_j^i \in {V_j} = \{v_1, \dots, v_k\}$ ($k$ depends on $j$)

**information entropy** of data $T$: 
$$
H(T) = -\sum_{y \in Y} p(y) \log p(y)
$$

**conditional information entropy** of $T$ given the attribute $a_j$: 

> predefine a set of $T$ for which attribute $a_j$ is equal to $v$: $S_j(v) = \{(\mathbf{x},y) \in T | x_j = v\} \leftarrow$

$$
H(T|a_j) = \sum_{v \in V_j} p_j(v) H(S_j(v)) = \sum_{v \in V_j} \frac{|S_j(v)|}{|T|} H(S_j(v))
$$

**information gain**: 
$$
IG(T, a_j) = H(T) - H(T|a_j)
$$

**intrinsic value information (split information)**:
$$
IV(T, a_j) = -\sum_{v \in V_j} \frac{|S_j(v)|}{|T|} \log \frac{|S_j(v)|}{|T|}
$$
**information gain ratio**: 
$$
IGR(T, a_j) = \frac{IG(T, a_j)}{IV(T, a_j)}
$$





## 3. Recommend

https://blog.csdn.net/tsyccnh/article/details/79163834

https://blog.csdn.net/rtygbwwwerr/article/details/50778098





交叉熵为什么越小越好

什么地方使用交叉熵，和MSE比较有什么好处呢



## 1. 信息论

the **informational value** of an event $x$ with probability $p(x)$ is:
$$
\mathrm{I}(x) = -\log(p(x))
$$
the **entropy** $Η$ of a discrete random variable $X$ with possible values $\left\{x_{1}, \ldots, x_{n}\right\}$ is:
$$
H(X)=\mathrm{E}[\mathrm{I}(X)]=\mathrm{E}[-\log (\mathrm{P}(X))]=-\sum_{i=1}^n p(x_i)\log p(x_i)
$$
**KLD (KL散度 也被称为相关熵)** the **relative entropy** (also called **Kullback–Leibler divergence**) of discrete probability distribution $p$ and $q$ defined on the same probability space $\mathcal{X}$ is:
$$
D_{\mathrm{KL}}(p \| q)=\sum_{x \in \mathcal{X}} p(x) \log \left(\frac{p(x)}{q(x)}\right)
$$
$$
D_{\mathrm{KL}}(p \| q)=\int_{-\infty}^{\infty} p(x) \log \left(\frac{p(x)}{q(x)}\right) dx
$$



the **cross entropy** of discrete probability distribution $p$ and $q$ with the same support $\mathcal{X}$ is:
$$
H(p, q) = -\mathrm{E}_{p}[\log q] = -\sum_{x \in \mathcal{X}} p(x) \log q(x)
$$
the relationship between relative entropy and cross entropy is:
$$
H(p, q)=H(p)+D_{\mathrm{KL}}(p \| q)
$$



the **information gain** is a synonym for KL divergence,

in the context of decision trees, it's the conditional expected value of KLD of the univariate probability distribution of one variable from the conditional distribution of this variable given the other one 



### Mutual information

the mutual information (MI) of two random variables is a measure of the mutual dependence between the two variables. 就是单变量香农熵的拓展。It’s coined by Robert Fano. It’s also known as information gain.

it quantifies the "amount of information"


$$
I(X ; Y)=H(X)-H(X \mid Y)=H(Y)-H(Y \mid X)
$$
properties:

- nonnegativity
- symmetry



In terms of PMFs for discrete distributions:
$$
\mathrm{I}(X ; Y)=\sum_{y \in \mathcal{Y}} \sum_{x \in \mathcal{X}} p_{(X, Y)}(x, y) \log \left(\frac{p_{(X, Y)}(x, y)}{p_{X}(x) p_{Y}(y)}\right)
$$
这时是可以用KL散度表示为 $\mathrm{I}(X ; Y)=D_{\mathrm{KL}}\left(p_{(X, Y)} \| p_{X} p_{Y}\right) = \mathbb{E}_{Y}\left[D_{\mathrm{KL}}\left(p_{X \mid Y} \| p_{X}\right)\right]$



In terms of PDFs for continuous distributions:
$$
\mathrm{I}(X ; Y)=\int_{\mathcal{Y}} \int_{\mathcal{X}} p_{(X, Y)}(x, y) \log \left(\frac{p_{(X, Y)}(x, y)}{p_{X}(x) p_{Y}(y)}\right) d x d y
$$
一些性质，如果X和Y是独立的，那么他们的互信息就等于0，因为$p(x,y) = p(x)p(y)$



## 几个常见分布

### 1.Gaussian

 $X \sim \mathcal{N}(\mu, \sigma^2)$
$$
p(x)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x - \mu)^{2}}{2 \sigma^{2}}}
$$
$E[X]=\mu, D[X]=\sigma^2$



The multivariate Gaussian distribution 多元高斯分布

 $\boldsymbol{x},\boldsymbol{\mu}$ are d-dimensional,  $\boldsymbol{x} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$
$$
p(\boldsymbol{x})==\frac{1}{(2 \pi)^{d / 2}|\boldsymbol{\Sigma}|^{1 / 2}} \exp \left\{-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{T} \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right\}
$$
$E[\boldsymbol{x}]=\boldsymbol{\mu}, D[\boldsymbol{x}]=\boldsymbol{\Sigma}$ 

$\frac{\partial p(\boldsymbol{x})}{\partial \boldsymbol{x}}=-p(\boldsymbol{x}) \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})$

### 2.Poisson

$$
p(x=k | \lambda)=\frac{1}{k !} e^{-\lambda} \lambda^{k}
$$

$E[X] = D[X] = \lambda$



### 3.Exponential

$$
p(x | \lambda)=\lambda e^{-\lambda x}
$$

$E[x]=\frac{1}{\lambda}, D[x]=\frac{1}{\lambda^2}$



###  二项分布、泊松分布、正态分布关系

1. 泊松分布，二项分布都是离散分布；正态分布是连续分布。

2. 二项分布什么时候趋近于泊松分布，什么时候趋近于正态分布？

   这么说吧：二项分布有两个参数，一个 n 表示试验次数，一个 p 表示一次试验成功概率。
   现在考虑一个二项分布，其中试验次数 n 无限增加，而 p 是 n 的函数。
   如果 np 存在有限极限 λ，则这列二项分布就趋于参数为 λ 的 泊松分布。反之，如果 np 趋于无限大（如 p 是一个定值），则根据德莫佛-拉普拉斯(De’Moivre-Laplace)中心极限定理，这列二项分布将趋近于正态分布。

   也就是说泊松分布和正态分布都来自于二项分布

3. 实际运用中当 n 很大时一般都用正态分布来近似计算二项分布，但是如果同时 np 又比较小（比起n来说很小），那么用泊松分布近似计算更简单些，毕竟泊松分布跟二项分布一样都是离散型分布。





### 理解记忆多维高斯分布

我们先看一维的正态分布：
$$
N\left(x| \mu, \sigma^{2}\right)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right)
$$
大家都没问题哈！

如果假设变量是相互独立的，那么可以得到变量的协方差矩阵的是对角矩阵
$$
\Sigma = \left[\begin{array}{cccc}{\sigma^2} & 0 & {\dots} & 0 \\ 0 & {\sigma^2} & {\dots} & 0 \\ {\dots} & {\dots} & {\dots} & {\dots} \\ 0 & 0 & {\dots} & {\sigma^2}\end{array}\right]
$$
x 是 d 维的向量， $\Sigma$ 是 x 的协方差矩阵
$$
N(x | u, \Sigma)=\frac{1}{(2 \pi)^{d/2}{|\Sigma|^{1 / 2}}} \exp \left[-\frac{1}{2}(x- u)^{T} \Sigma^{-1}(x-u)\right]
$$



## 样本估计

we have the **population mean** $\mu$ , **population variance** $\sigma^2$ 

i.e  $E[X]=\mu$                   $D[X]=E[(x-E[X])]^2=\sigma^2$

now we have the sample $x_1,x_2,\dots,x_n$ 

for each sample, $E[x_i] =\mu$ ,  $D[x_i]=\sigma^2$ 

sample mean $\overline{x}=\frac{1}{n}\sum_{i=1}^{n}x_i$  ; sample variance $S^2=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\overline{x})^2$ 

we want to see the bias between sample mean/variance and population mean/variance 

we can see the sample mean expectation:

$$
E[\overline{x}]=E[\frac{1}{n}\sum_{i=1}^{n}x_i]=\frac{1}{n}\sum_{i=1}^{n}E[x_i]=\frac{1}{n}\sum_{i=1}^{n}\mu=\mu
$$

**it is unbiased expectation** , and we can also get : 
$$
D[\overline{x}]=D[\frac{1}{n}\sum_{i=1}^{n}x_i]=\frac{1}{n^2}\sum_{i=1}^{n}D[x_i]=\frac{1}{n}\sigma^2
$$
we can see the sample variance expectation:

$$
\begin{aligned}
E[S^2]=E[\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\overline{x})^2]
&=\frac{1}{n-1}\sum_{i=1}^{n}E[(x_i-\overline{x})^2]\\
&=\frac{1}{n-1}\sum_{i=1}^{n}E\left(x_i^2-2x_i\overline{x} + \overline{x}^2\right)\\
&=\frac{1}{n-1}\left(\sum_{i=1}^{n}E[x_i^2]-2\sum_{i=1}^{n}E[x_i\overline{x}]+\sum_{i=1}^{n}E[\overline{x}^2] \right)\\
&=\frac{1}{n-1}\left(\sum_{i=1}^{n}E[x_i^2]
-2E[\overline{x}\sum_{i=1}^{n}x_i]
+nE[\overline{x}^2] \right)\\
&=\frac{1}{n-1}\left(\sum_{i=1}^{n}E[x_i^2]
-2E[\overline{x}n\overline{x}]
+nE[\overline{x}^2] \right)\\
&=\frac{1}{n-1}\left(\sum_{i=1}^{n}E[x_i^2]
-2nE[\overline{x}^2]
+nE[\overline{x}^2] \right)\\
&=\frac{1}{n-1}\left(\sum_{i=1}^{n}E[x_i^2]
-nE[\overline{x}^2] \right)\\
&=\frac{1}{n-1}\left(\sum_{i=1}^{n}(D[x_i]+{E[x_i]}^2)
-n(D[\overline{x}]+{E[\overline{x}]}^2) \right)\\
&=\frac{1}{n-1}\left(n(\sigma^2+\mu^2)
-n(\frac{1}{n}\sigma^2+\mu^2) \right)\\
&=\sigma^2
\end{aligned}
$$

**it is unbiased expectation** , so the denominator should be (n-1)

估计量的数学期望等于被估计参数的真实值，在多次重复下，它们的平均数接近所估计的参数真值 

Bias of an estimator :  is the difference between this estimator's expected value and the true value of the parameter being estimated. 







参考

[Univariate Distribution Relationships](http://www.math.wm.edu/~leemis/2008amstat.pdf)







## 贝叶斯 Bayes


$$
p(\theta) = \int_{\Theta} f(x \mid \theta) \pi(\theta) \mathrm{d} \theta
$$






$$
D_{K L}(p(A, B) \| p(A))=\sum_{a \in A} \sum_{b \in B} p(a, b) \log \frac{p(a, b)}{p(a)}
$$

$$
D_{KL}(q(z|x)\|p(z)) = \mathbb{E}_{q(z|x)}\left[\log \frac{q(z|x)}{p(z)}\right]
$$

$$
D_{\mathrm{KL}}\left(q_\phi(\boldsymbol{z} \mid \boldsymbol{x}) \| p(\boldsymbol{z} \mid \boldsymbol{x})\right) = \mathbb{E}_{q_\phi(\boldsymbol{z} \mid \boldsymbol{x})}\left[\log \frac{q_{\boldsymbol{\phi}}(\boldsymbol{z} \mid \boldsymbol{x})}{p(\boldsymbol{z} \mid \boldsymbol{x})}\right]
$$

$$
D_{KL} [q(z)\|p(z)]= \int q(z) \log \frac{q(z)}{p(z)} \mathrm{d} z 
$$

$$
K L[q(u \mid v) \| p(u \mid v)] = \mathbb{E}_{q(v)} \left[\int q(u \mid v) \log \frac{q(u \mid v)}{p(u \mid v))} \mathrm{d} u \right]
$$




chain rule and random variables 
$$
\begin{aligned}
\mathrm{P}\left(X_4, X_3, X_2, X_1\right) &=\mathrm{P}\left(X_4 \mid X_3, X_2, X_1\right) \cdot \mathrm{P}\left(X_3, X_2, X_1\right) \\
&=\mathrm{P}\left(X_4 \mid X_3, X_2, X_1\right) \cdot \mathrm{P}\left(X_3 \mid X_2, X_1\right) \cdot \mathrm{P}\left(X_2, X_1\right) \\
&=\mathrm{P}\left(X_4 \mid X_3, X_2, X_1\right) \cdot \mathrm{P}\left(X_3 \mid X_2, X_1\right) \cdot \mathrm{P}\left(X_2 \mid X_1\right) \cdot \mathrm{P}\left(X_1\right)
\end{aligned}
$$

$$
E[g(X, Y)]=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x, y) \cdot f(x, y) d x d y
$$



$$
\begin{aligned}
E[X Y] &=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x y f(x, y) d x d y \\
&=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x y f_X(x) f_Y(y) d x d y \\
&=\int_{-\infty}^{\infty} y f_Y(y) \underbrace{\int_{-\infty}^{\infty} x f_X(x) d x}_{E[X]} d y \\
&=E[X] E[Y] .
\end{aligned}
$$






https://dlsun.github.io/probability/ev-joint-continuous.html

https://threeplusone.com/pubs/on_information.pdf
