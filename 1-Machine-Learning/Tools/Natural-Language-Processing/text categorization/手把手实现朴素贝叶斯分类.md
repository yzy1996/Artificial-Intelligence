# 手把手实现朴素贝叶斯分类



## 预知识





## 第一步

计算 **Term-Document Matrix**(TDM) ，矩阵是每个单词在文档中出现的词频

矩阵的格式不固定，sklearn中的CountVectorizer得到的矩阵，$X[i][j]$ 表示第j个词在第i个文本中的词频，举个例子

~~~python
>>> from sklearn.feature_extraction.text import CountVectorizer
>>> corpus = [
...     'This is the first document.',
...     'This document is the second document.',
...     'And this is the third one.',
...     'Is this the first document?',
... ]
>>> vectorizer = CountVectorizer()
>>> X = vectorizer.fit_transform(corpus)
>>> print(vectorizer.get_feature_names())
['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']
>>> print(X.toarray())
[[0 1 1 1 0 0 1 0 1]
 [0 2 0 1 0 1 1 0 1]
 [1 0 0 1 1 0 1 1 1]
 [0 1 1 1 0 0 1 0 1]]
~~~



 # 第三步 

我们要使用朴素贝叶斯决策

其实要解决的是一个很简单的问题，



我们通过前面几步得到了什么呢？

我们知道了$word_1, \dots, word_n$



朴素的意思是假设每个单词是相互独立的

我们现在知道类别 Spam|Ham



 https://zhuanlan.zhihu.com/p/52728190 