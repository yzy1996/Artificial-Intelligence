{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75ASwl6JuHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vm6Rt4Q5OZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, intermediate_dim, original_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_layer = tf.keras.layers.Dense(\n",
        "      units=intermediate_dim,\n",
        "      activation=tf.nn.relu,\n",
        "      kernel_initializer='he_uniform'\n",
        "    )\n",
        "    self.output_layer = tf.keras.layers.Dense(\n",
        "      units=original_dim,\n",
        "      activation=tf.nn.sigmoid\n",
        "    )\n",
        "  \n",
        "  def call(self, code):\n",
        "    activation = self.hidden_layer(code)\n",
        "    return self.output_layer(activation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugjzO3_l5Wme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(tf.keras.Model):\n",
        "  def __init__(self, intermediate_dim, original_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = Encoder(intermediate_dim=intermediate_dim)\n",
        "    self.decoder = Decoder(intermediate_dim=intermediate_dim, original_dim=original_dim)\n",
        "  \n",
        "  def call(self, input_features):\n",
        "    code = self.encoder(input_features)\n",
        "    reconstructed = self.decoder(code)\n",
        "    return reconstructed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rgpQINM5tbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(model, original):\n",
        "  reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(model(original), original)))\n",
        "  return reconstruction_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvb4X-W5xd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(loss, model, opt, original):\n",
        "  with tf.GradientTape() as tape:\n",
        "    gradients = tape.gradient(loss(model, original), model.trainable_variables)\n",
        "    gradient_variables = zip(gradients, model.trainable_variables)\n",
        "    opt.apply_gradients(gradient_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2ITUH6-6FSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "autoencoder = Autoencoder(intermediate_dim=64, original_dim=784)\n",
        "opt = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "(training_features, _), (test_features, _) = tf.keras.datasets.mnist.load_data()\n",
        "training_features = training_features / np.max(training_features)\n",
        "training_features = training_features.reshape(training_features.shape[0],\n",
        "                                              training_features.shape[1] * training_features.shape[2])\n",
        "training_features = training_features.astype('float32')\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices(training_features)\n",
        "training_dataset = training_dataset.batch(batch_size)\n",
        "training_dataset = training_dataset.shuffle(training_features.shape[0])\n",
        "training_dataset = training_dataset.prefetch(batch_size * 4)\n",
        "\n",
        "writer = tf.summary.create_file_writer('tmp')\n",
        "\n",
        "with writer.as_default():\n",
        "  with tf.summary.record_if(True):\n",
        "    for epoch in range(epochs):\n",
        "      for step, batch_features in enumerate(training_dataset):\n",
        "        train(loss, autoencoder, opt, batch_features)\n",
        "        loss_values = loss(autoencoder, batch_features)\n",
        "        original = tf.reshape(batch_features, (batch_features.shape[0], 28, 28, 1))\n",
        "        reconstructed = tf.reshape(autoencoder(tf.constant(batch_features)), (batch_features.shape[0], 28, 28, 1))\n",
        "        tf.summary.scalar('loss', loss_values, step=step)\n",
        "        tf.summary.image('original', original, max_outputs=10, step=step)\n",
        "        tf.summary.image('reconstructed', reconstructed, max_outputs=10, step=step)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqAONmgG1elL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "\n",
        "(x_train, _), _ = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32').reshape((-1, 28*28)) / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji2EswI02qsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
        "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
        "# encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
        "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
        "# decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
        "# autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}