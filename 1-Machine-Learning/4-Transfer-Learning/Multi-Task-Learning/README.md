<h1 align="center">Multi-Task Learning</h1>
<div align="center">
Introduction  
</div>

## Definition

By sharing representations between related tasks, we can enable our model to generalize better on our original task. This approach is called Multi-Task Learning (MTL).



又名 joint learning, learning to learn, learning with auxiliary task

## Papers

[Pareto Multi-Task Learning](https://papers.nips.cc/paper/9374-pareto-multi-task-learning.pdf)

multiple loss:

[Deep Network Interpolation for Continuous Imagery Effect Transition](https://arxiv.org/abs/1811.10515)

[Dynamic-Net: Tuning the Objective Without Re-training for Synthesis Tasks](http://export.arxiv.org/abs/1811.08760)

hypernetworks:

[HyperNetworks](https://arxiv.org/abs/1609.09106)

conditional training to multiple loss:

[You Only Train Once: Loss-Conditional Training of Deep Networks](https://openreview.net/forum?id=HyxY6JHKwr)

hypernetworks to continual learning:

[Continual learning with hypernetworks](https://openreview.net/forum?id=SJgwNerKvB&noteId=rkludeIKiS)

## Code

https://github.com/Xi-L/ParetoMTL