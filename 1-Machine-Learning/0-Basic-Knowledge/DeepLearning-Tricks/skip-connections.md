# Skip Connection

The earliest literature is [Deep Residual Learning for Image Recognition](http://arxiv.org/abs/1512.03385) released by Microsoft on ImageNet 2015 Competition.



The problem motivated them is the following:

> When deeper networks are able to start converging, a *degradation* problem has been exposed: with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly. Unexpectedly, such degradation is *not caused by overfitting*, and adding more layers to a suitably deep model leads to *higher training error*



![enter image description here](https://i.stack.imgur.com/gSxcB.png)


$$
 
$$




[link](https://theaisummer.com/skip-connections/)

[link](https://stats.stackexchange.com/questions/56950/neural-network-with-skip-layer-connections)





训练更快？精度更高？