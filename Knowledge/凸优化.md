# 凸优化

线性规划和非线性规划



## 一、判断凹凸性



### 1. 定义

定义域 $dom f$ 是凸集，且 $f(\theta x+(1-\theta) y) \leqslant \theta f(x)+(1-\theta) f(y)$ $（0\leq \theta \leq 1）$



### 2. 判定

**一阶条件**

凸函数位于切线上
$$
f(y) \geqslant f(x)+\nabla f(x)^{T}(y-x)
$$
**二阶条件**

凸函数曲率非负
$$
\text{Hessian矩阵半正定}
$$

$$
\nabla^{2} f(x) \succeq 0
$$

半正定判断[参考]()



### 3. 常见的一些凸函数：

- $x^{p}$ for $p \geq 1$ or $p \leq 0 ;-x^{p}$ for $0 \leq p \leq 1$

- $e^{x},-\log x, x \log x$

- $a^{T} x+b$

- $x^{T} x ; x^{T} x / y(\text { for } y>0) ;\left(x^{T} x\right)^{1 / 2}$

- $\|x\|$ (any norm)

- $\max \left(x_{1}, \ldots, x_{n}\right), \log \left(e^{x_{1}}+\cdots+e^{x_{n}}\right)$

- $\log \Phi(x) $($\Phi$ is Gaussian CDF )

- $\log \operatorname{det} X^{-1}(\text {for } X \succ 0)$

  

### 4. 运算规则

- 非负缩放： if $f$ is convex, $\alpha \geq 0,$ then $\alpha f$ is convex

- 求和： if $f$ and $g$ are convex, so is $f+g$
- 仿射： if $f$ is convex, so is $f(A x+b)$
- 逐点最大： if $f_{1}, \ldots, f_{m}$ are convex, so is $f(x)=\max _{i} f_{i}(x)$
- 局部最小： if $f(x, y)$ is convex, and $C$ is convex, then $g(x)=\inf _{y \in C} f(x, y)$ is convex
- 组合： if $h$ is convex and increasing, and $f$ is convex, then $g(x)=h(f(x))$ is convex

注意：避免2个凸函数相乘，避免两个凸函数相减



### 5.补充

- $log(f)$ 凸可以推出 $f$ 凸，反过来不行

> $$
> (\log f(x))^{\prime \prime}=\left(\frac{f^{\prime}(x)}{f(x)}\right)^{\prime}=\frac{f(x) f^{\prime \prime}(x)-\left(f^{\prime}(x)\right)^{2}}{f^{2}(x)}
> $$
>
> 如果 $(\log f(x))'' \geq 0$， 则 $f''(x) \geq 0$ 



- 詹森不等式拓展

$$
f(y) \geqslant f(x)+\nabla f(x)^{T}(y-x)
$$

如果 $f$ 是凸函数，且 $\sum_{i} \theta_{i}=1, \theta \succeq 0$， 则：
$$
f\left(\sum_{i} \theta_{i} x_{i}\right) \leq \sum_{i} \theta_{i} f\left(x_{i}\right)
$$
如果 $f$ 是凸函数，且 $\int_{S} p(x) d x=1$，则：
$$
f\left(\int_{S} x p(x) d x\right) \leq \int_{S} p(x) f(x) d x
$$






Gamma函数

### 6.  一些不那么容易的例子

- $f(x)=x_{1}^{\theta_{1}} \ldots x_{n}^{\theta_{n}}$ , when $\theta \geq 0$ and $1^T \theta \leq 1$, $f$ is concave.

>
> $$
> f(x)=\prod_{i} x_{i}^{\theta_{i}}
> $$
>
> $$
> \frac{\partial^{2} f}{\partial x_{i}^{2}}=\frac{\theta_{i}\left(\theta_{i}-1\right)}{x_{i}^{2}} \prod_{i} x_{i}^{\theta_{i}}
> $$
>
> $$
> \frac{\partial^{2} f}{\partial x_{i} x_{j}}=\frac{\theta_{i} \theta_{j}}{x_{i} x_{j}} \prod_{i} x_{i}^{\theta_{i}}
> $$
>
> Hence, we get the Hessian as:
>
> $$
>\nabla^{2} f(x)=\left(\prod_{i} x_{i}^{\theta_{i}}\right)\left[\operatorname{diag}\left(-\theta_{1} / x_{1}^{2}, \ldots,-\theta_{n} / x_{n}^{2}\right)+t t^{T}\right]
> $$
> 
> where $t_i = \theta_i / x_i$
>
> If $f(x)$ is concave, then $v^{T} \nabla^{2} f(x) v \leq 0$ for all $v \in \mathbf{R}^{n}$ 
>
> $$
>v^{T}\left[\operatorname{diag}\left(-\theta_{1} / x_{1}^{2}, \ldots,-\theta_{n} / x_{n}^{2}\right)+q q^{T}\right] v=\left(\sum_{i} \frac{\theta_{i} v_{i}}{x_{i}}\right)^{2}- \left(\sum_{i} \theta_{i} \frac{v_{i}^{2}}{x_{i}^{2}}\right)
> $$
> 
> And according to Cauchy-Schwarz inequality, 
>
> $$
>\left(\sum_{i} \frac{\theta_{i} v_{i}}{x_{i}}\right)^{2} \leq\left(\sum_{i} \theta_{i}\right)\left(\sum_{i} \theta_{i} \frac{v_{i}^{2}}{x_{i}^{2}}\right)
> $$
> 
> and because $1^T\theta \leq 1$, so 
>
> $$
>\left(\sum_{i} \frac{\theta_{i} v_{i}}{x_{i}}\right)^{2} \leq \left(\sum_{i} \theta_{i} \frac{v_{i}^{2}}{x_{i}^{2}}\right)
> $$
> 
> so $v^{T} \nabla^{2} f(x) v \leq 0$ is proved! And this statement is proved!





### 7. 利用程序判断

借助 [cvxpy](https://www.cvxpy.org/index.html) 判断曲率

```python
import cvxpy as cp

x = cp.Variable()
y = x ** 2

print(y.curvature)
```

